{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: numpy in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: torch in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: transformers in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (4.45.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: torchvision in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: tqdm in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (4.66.5)\n",
      "Requirement already satisfied: matplotlib in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: filelock in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/adamds/.local/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: packaging in /Users/adamds/.local/lib/python3.8/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/adamds/.local/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/adamds/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adamds/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch faiss-cpu transformers sentencepiece torchvision tqdm matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: ipywidgets in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/adamds/.local/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/adamds/.local/lib/python3.8/site-packages (from ipywidgets) (8.12.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/adamds/.local/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/adamds/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/adamds/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/adamds/.local/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/adamds/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/adamds/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/adamds/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/adamds/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/adamds/.local/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a24eabe0f04b32b599a0c73a4f698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple\n",
      "Requirement already satisfied: tqdm in /Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages (4.66.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import faiss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks loaded: 400\n"
     ]
    }
   ],
   "source": [
    "# Define paths to the ARC dataset\n",
    "arc_dataset_path = 'data/training'  # Adjust this path\n",
    "\n",
    "# Function to load ARC tasks\n",
    "def load_arc_tasks(task_dir):\n",
    "    tasks = []\n",
    "    for filename in os.listdir(task_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(task_dir, filename), 'r') as f:\n",
    "                task = json.load(f)\n",
    "                tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "# Load all tasks\n",
    "all_tasks = load_arc_tasks(arc_dataset_path)\n",
    "print(f\"Total tasks loaded: {len(all_tasks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tasks: 320\n",
      "Testing tasks: 80\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the tasks\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "# Split into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(all_tasks))\n",
    "train_tasks = all_tasks[:split_index]\n",
    "test_tasks = all_tasks[split_index:]\n",
    "\n",
    "print(f\"Training tasks: {len(train_tasks)}\")\n",
    "print(f\"Testing tasks: {len(test_tasks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symbols: 10\n"
     ]
    }
   ],
   "source": [
    "# Define maximum grid size\n",
    "MAX_GRID_SIZE = 30  # Adjust based on the dataset\n",
    "\n",
    "# Function to preprocess grids\n",
    "def preprocess_grid(grid, max_size=MAX_GRID_SIZE):\n",
    "    height = len(grid)\n",
    "    width = len(grid[0])\n",
    "    # Initialize a grid filled with zeros\n",
    "    processed_grid = np.zeros((max_size, max_size), dtype=np.int64)\n",
    "    # Copy the original grid into the processed grid\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            processed_grid[i, j] = grid[i][j]\n",
    "    return processed_grid\n",
    "\n",
    "# Build a set of all colors/symbols used in the dataset\n",
    "symbols = set()\n",
    "for task in train_tasks:\n",
    "    for example in task['train']:\n",
    "        for row in example['input']:\n",
    "            symbols.update(row)\n",
    "        for row in example['output']:\n",
    "            symbols.update(row)\n",
    "\n",
    "symbol_to_int = {symbol: idx for idx, symbol in enumerate(sorted(symbols))}\n",
    "int_to_symbol = {idx: symbol for symbol, idx in symbol_to_int.items()}\n",
    "num_symbols = len(symbol_to_int)\n",
    "print(f\"Total unique symbols: {num_symbols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_symbols=num_symbols):\n",
    "        super(GridEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_symbols, 16)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduces spatial dimensions by half\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduces spatial dimensions by half again\n",
    "        )\n",
    "        # The fc layer will be initialized dynamically\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)  # Use contiguous before view\n",
    "\n",
    "        if self.fc is None:\n",
    "            self.fc = nn.Linear(x.size(1), 128).to(x.device)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGridDataset(Dataset):\n",
    "    def __init__(self, tasks):\n",
    "        self.samples = []\n",
    "        for task in tasks:\n",
    "            for example in task['train']:\n",
    "                input_grid = preprocess_grid(example['input'])\n",
    "                output_grid = preprocess_grid(example['output'])\n",
    "                self.samples.append((input_grid, output_grid))\n",
    "\n",
    "        # Create negatives by shuffling outputs\n",
    "        self.negatives = [output for _, output in self.samples]\n",
    "        random.shuffle(self.negatives)\n",
    "\n",
    "        # Map symbols to integers\n",
    "        self.symbol_to_int = symbol_to_int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_grid, positive_grid = self.samples[idx]\n",
    "        negative_grid = self.negatives[idx]\n",
    "\n",
    "        # Convert grids to tensors and map symbols to integers\n",
    "        anchor = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in anchor_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        positive = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in positive_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        negative = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in negative_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return anchor, positive, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 33/33 [00:03<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 33/33 [00:02<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 33/33 [00:02<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 33/33 [00:02<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 33/33 [00:02<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.3568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset and data loader\n",
    "triplet_dataset = TripletGridDataset(train_tasks)\n",
    "triplet_loader = DataLoader(triplet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the encoder and move it to the device\n",
    "encoder = GridEncoder().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(tqdm(triplet_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        anchor_emb = encoder(anchor)\n",
    "        positive_emb = encoder(positive)\n",
    "        negative_emb = encoder(negative)\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(triplet_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding input grids: 100%|██████████| 1051/1051 [00:00<00:00, 2406.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 1051 embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect all input grids and their indices\n",
    "all_input_grids = []\n",
    "grid_indices = []\n",
    "for task_idx, task in enumerate(train_tasks):\n",
    "    for example_idx, example in enumerate(task['train']):\n",
    "        input_grid = preprocess_grid(example['input'])\n",
    "        all_input_grids.append(input_grid)\n",
    "        grid_indices.append((task_idx, example_idx))\n",
    "\n",
    "# Encode all input grids\n",
    "encoder.eval()\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for grid in tqdm(all_input_grids, desc=\"Encoding input grids\"):\n",
    "        grid_tensor = torch.tensor(\n",
    "            [[symbol_to_int.get(cell, 0) for cell in row] for row in grid],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        embedding = encoder(grid_tensor)\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings_np = np.vstack(embeddings).astype('float32')\n",
    "\n",
    "# Build the FAISS index\n",
    "embedding_dim = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings_np)\n",
    "print(f\"FAISS index built with {index.ntotal} embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_examples(input_grid, k=4):\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        grid_tensor = torch.tensor(\n",
    "            [[symbol_to_int.get(cell, 0) for cell in row] for row in preprocess_grid(input_grid)],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        input_embedding = encoder(grid_tensor).cpu().numpy()\n",
    "    D, I = index.search(input_embedding, k)\n",
    "    similar_examples = []\n",
    "    for idx in I[0]:\n",
    "        task_idx, example_idx = grid_indices[idx]\n",
    "        sim_input_grid = all_input_grids[idx]\n",
    "        sim_output_grid = preprocess_grid(train_tasks[task_idx]['train'][example_idx]['output'])\n",
    "        similar_examples.append((sim_input_grid, sim_output_grid))\n",
    "    return similar_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-125M\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_text(grid):\n",
    "    grid = grid[:MAX_GRID_SIZE, :MAX_GRID_SIZE]\n",
    "    text = '\\n'.join([' '.join(map(str, row)) for row in grid])\n",
    "    return text\n",
    "\n",
    "def create_prompt(similar_examples, input_grid):\n",
    "    prompt = \"Below are examples of input grids and their corresponding output grids:\\n\\n\"\n",
    "    for idx, (sim_input, sim_output) in enumerate(similar_examples):\n",
    "        prompt += f\"Example {idx+1}:\\nInput:\\n{grid_to_text(sim_input)}\\n\"\n",
    "        prompt += f\"Output:\\n{grid_to_text(sim_output)}\\n\\n\"\n",
    "    prompt += \"Now, given the following input grid:\\n\"\n",
    "    prompt += f\"{grid_to_text(preprocess_grid(input_grid))}\\n\\n\"\n",
    "    prompt += \"Please provide the corresponding output grid.\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    max_length = min(1024, input_ids.shape[1] + 200)  # Adjust as needed\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return output_text[len(prompt):].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output_grid(response_text):\n",
    "    # Attempt to extract the grid after \"Output:\"\n",
    "    if \"Output:\" in response_text:\n",
    "        output_section = response_text.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        output_section = response_text.strip()\n",
    "    grid_lines = output_section.split('\\n')\n",
    "    output_grid = []\n",
    "    for line in grid_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            row = [int(s) for s in line.strip().split()]\n",
    "            output_grid.append(row)\n",
    "        except ValueError:\n",
    "            # Handle lines that don't contain integers\n",
    "            continue\n",
    "    if output_grid:\n",
    "        return output_grid\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def update_embedding_database(input_grid, output_grid):\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(\n",
    "            [[symbol_to_int.get(cell, 0) for cell in row] for row in preprocess_grid(input_grid)],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        embedding = encoder(input_tensor).cpu().numpy()\n",
    "    index.add(embedding)\n",
    "    all_input_grids.append(preprocess_grid(input_grid))\n",
    "    grid_indices.append((-1, -1))  # Indicate that this is a new addition\n",
    "    # Optionally, you can store the output_grid if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal test code\n",
    "try:\n",
    "    # Test on a single example\n",
    "    test_task = test_tasks[0]  # Select the first test task\n",
    "    example = test_task['test'][0]  # Select the first example in the task\n",
    "\n",
    "    print(\"Processing input grid...\")\n",
    "    input_grid = example['input']\n",
    "    print(f\"Input Grid: {input_grid}\")\n",
    "\n",
    "    expected_output = example.get('output', None)\n",
    "    if expected_output:\n",
    "        print(f\"Expected Output: {expected_output}\")\n",
    "        \n",
    "        print(\"Retrieving similar examples...\")\n",
    "        similar_examples = retrieve_similar_examples(input_grid)  # Ensure this is defined\n",
    "        print(f\"Similar Examples: {similar_examples}\")\n",
    "\n",
    "        print(\"Creating prompt...\")\n",
    "        prompt = create_prompt(similar_examples, input_grid)  # Ensure this is defined\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "\n",
    "        print(\"Generating output...\")\n",
    "        output_text = generate_output(prompt)  # Ensure this is defined\n",
    "        print(f\"Output Text: {output_text}\")\n",
    "\n",
    "        print(\"Extracting output grid...\")\n",
    "        predicted_output = extract_output_grid(output_text)  # Ensure this is defined\n",
    "        print(f\"Predicted Output: {predicted_output}\")\n",
    "\n",
    "        is_correct = grids_are_equal(predicted_output, expected_output) if predicted_output else False\n",
    "        print(f\"Correct: {is_correct}\")\n",
    "    else:\n",
    "        print(\"No expected output provided for this test task.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
