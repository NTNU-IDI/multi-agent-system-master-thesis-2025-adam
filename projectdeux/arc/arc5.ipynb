{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (if not already installed)\n",
    "# !pip install numpy torch faiss-cpu transformers sentencepiece torchvision tqdm matplotlib ipywidgets\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import faiss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm.notebook import tqdm  # Use notebook version for Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks loaded: 400\n"
     ]
    }
   ],
   "source": [
    "# Define paths to the ARC dataset\n",
    "arc_dataset_path = 'data/training'  # Adjust this path\n",
    "\n",
    "# Function to load ARC tasks\n",
    "def load_arc_tasks(task_dir):\n",
    "    tasks = []\n",
    "    for filename in os.listdir(task_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(task_dir, filename), 'r') as f:\n",
    "                task = json.load(f)\n",
    "                tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "# Load all tasks\n",
    "all_tasks = load_arc_tasks(arc_dataset_path)\n",
    "print(f\"Total tasks loaded: {len(all_tasks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 tasks for testing.\n"
     ]
    }
   ],
   "source": [
    "# For testing purposes, limit the number of tasks\n",
    "num_tasks = 10  # Adjust this number based on available resources\n",
    "all_tasks = random.sample(all_tasks, num_tasks)\n",
    "print(f\"Using {num_tasks} tasks for testing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tasks: 8\n",
      "Testing tasks: 2\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the tasks\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "# Split into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(all_tasks))\n",
    "train_tasks = all_tasks[:split_index]\n",
    "test_tasks = all_tasks[split_index:]\n",
    "\n",
    "print(f\"Training tasks: {len(train_tasks)}\")\n",
    "print(f\"Testing tasks: {len(test_tasks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symbols: 9\n"
     ]
    }
   ],
   "source": [
    "# Define maximum grid size\n",
    "MAX_GRID_SIZE = 30  # Adjust based on the dataset\n",
    "\n",
    "# Function to preprocess grids\n",
    "def preprocess_grid(grid, max_size=MAX_GRID_SIZE):\n",
    "    height = len(grid)\n",
    "    width = len(grid[0])\n",
    "    # Initialize a grid filled with zeros\n",
    "    processed_grid = np.zeros((max_size, max_size), dtype=np.int64)\n",
    "    # Copy the original grid into the processed grid\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            processed_grid[i, j] = grid[i][j]\n",
    "    return processed_grid\n",
    "\n",
    "# Build a set of all colors/symbols used in the dataset\n",
    "symbols = set()\n",
    "for task in train_tasks:\n",
    "    for example in task['train']:\n",
    "        for row in example['input']:\n",
    "            symbols.update(row)\n",
    "        for row in example['output']:\n",
    "            symbols.update(row)\n",
    "\n",
    "symbol_to_int = {symbol: idx for idx, symbol in enumerate(sorted(symbols))}\n",
    "int_to_symbol = {idx: symbol for symbol, idx in symbol_to_int.items()}\n",
    "num_symbols = len(symbol_to_int)\n",
    "print(f\"Total unique symbols: {num_symbols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_symbols=num_symbols):\n",
    "        super(GridEncoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim  # Store embedding_dim as an instance variable\n",
    "        self.embedding = nn.Embedding(num_symbols, 16)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduces spatial dimensions by half\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduces spatial dimensions by half again\n",
    "        )\n",
    "        # The fc layer will be initialized dynamically\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.contiguous().view(x.size(0), -1)  # Use contiguous before view\n",
    "\n",
    "        if self.fc is None:\n",
    "            self.fc = nn.Linear(x.size(1), self.embedding_dim).to(x.device)  # Use self.embedding_dim\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGridDataset(Dataset):\n",
    "    def __init__(self, tasks):\n",
    "        self.samples = []\n",
    "        for task in tasks:\n",
    "            for example in task['train']:\n",
    "                input_grid = preprocess_grid(example['input'])\n",
    "                output_grid = preprocess_grid(example['output'])\n",
    "                self.samples.append((input_grid, output_grid))\n",
    "\n",
    "        # Create negatives by shuffling outputs\n",
    "        self.negatives = [output for _, output in self.samples]\n",
    "        random.shuffle(self.negatives)\n",
    "\n",
    "        # Map symbols to integers\n",
    "        self.symbol_to_int = symbol_to_int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_grid, positive_grid = self.samples[idx]\n",
    "        negative_grid = self.negatives[idx]\n",
    "\n",
    "        # Convert grids to tensors and map symbols to integers\n",
    "        anchor = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in anchor_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        positive = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in positive_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        negative = torch.tensor(\n",
    "            [[self.symbol_to_int.get(cell, 0) for cell in row] for row in negative_grid],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return anchor, positive, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8591cccc4f3143d8bfb8c1b855d03491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.8882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b02488f342a4588b3e7971032bb7cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.7268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178f6353b30449ae9fb3cae14a0ec21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.5911\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset and data loader\n",
    "triplet_dataset = TripletGridDataset(train_tasks)\n",
    "triplet_loader = DataLoader(triplet_dataset, batch_size=8, shuffle=True)  # Reduced batch size\n",
    "\n",
    "# Initialize the encoder and move it to the device\n",
    "encoder = GridEncoder().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(tqdm(triplet_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        anchor_emb = encoder(anchor)\n",
    "        positive_emb = encoder(positive)\n",
    "        negative_emb = encoder(negative)\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(triplet_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f73e0688c84f7ab48e04a955629597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding input grids:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 26 embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Collect all input grids and their indices\n",
    "all_input_grids = []\n",
    "grid_indices = []\n",
    "for task_idx, task in enumerate(train_tasks):\n",
    "    for example_idx, example in enumerate(task['train']):\n",
    "        input_grid = preprocess_grid(example['input'])\n",
    "        all_input_grids.append(input_grid)\n",
    "        grid_indices.append((task_idx, example_idx))\n",
    "\n",
    "# Encode all input grids\n",
    "encoder.eval()\n",
    "embeddings = []\n",
    "\n",
    "encode_batch_size = 16\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(all_input_grids), encode_batch_size), desc=\"Encoding input grids\"):\n",
    "        batch_grids = all_input_grids[i:i+encode_batch_size]\n",
    "        batch_tensors = []\n",
    "        for grid in batch_grids:\n",
    "            grid_tensor = torch.tensor(\n",
    "                [[symbol_to_int.get(cell, 0) for cell in row] for row in grid],\n",
    "                dtype=torch.long\n",
    "            )\n",
    "            batch_tensors.append(grid_tensor)\n",
    "        batch_tensors = torch.stack(batch_tensors).to(device)\n",
    "        batch_embeddings = encoder(batch_tensors)\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "embeddings_np = np.vstack(embeddings).astype('float32')\n",
    "\n",
    "# Build the FAISS index\n",
    "embedding_dim = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings_np)\n",
    "print(f\"FAISS index built with {index.ntotal} embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_examples(input_grid, k=4):\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        grid_tensor = torch.tensor(\n",
    "            [[symbol_to_int.get(cell, 0) for cell in row] for row in preprocess_grid(input_grid)],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        input_embedding = encoder(grid_tensor).cpu().numpy()\n",
    "    D, I = index.search(input_embedding, k)\n",
    "    similar_examples = []\n",
    "    for idx in I[0]:\n",
    "        task_idx, example_idx = grid_indices[idx]\n",
    "        sim_input_grid = all_input_grids[idx]\n",
    "        sim_output_grid = preprocess_grid(train_tasks[task_idx]['train'][example_idx]['output'])\n",
    "        similar_examples.append((sim_input_grid, sim_output_grid))\n",
    "    return similar_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbb8bad4a4e44b999b7a933981dc2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558aae579f8644229ebd4f8dfb6015b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376f91f2948446bab70dbee45eafbc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765319d035ae4161bad40855fe9874db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8767ce7aea47d29357252f08ec862f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamds/.pyenv/versions/3.8.12/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41c3c4704f44b679cf9de3191ddc034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2e66811fa243e588d9f4ceafcb1252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_text(grid):\n",
    "    grid = grid[:MAX_GRID_SIZE, :MAX_GRID_SIZE]\n",
    "    text = '\\n'.join([' '.join(map(str, row)) for row in grid])\n",
    "    return text\n",
    "\n",
    "def create_prompt(similar_examples, input_grid):\n",
    "    prompt = \"Below are examples of input grids and their corresponding output grids:\\n\\n\"\n",
    "    for idx, (sim_input, sim_output) in enumerate(similar_examples):\n",
    "        prompt += f\"Example {idx+1}:\\nInput:\\n{grid_to_text(sim_input)}\\n\"\n",
    "        prompt += f\"Output:\\n{grid_to_text(sim_output)}\\n\\n\"\n",
    "    prompt += \"Now, given the following input grid:\\n\"\n",
    "    prompt += f\"{grid_to_text(preprocess_grid(input_grid))}\\n\\n\"\n",
    "    prompt += \"Please provide the corresponding output grid.\"\n",
    "    return prompt\n",
    "\n",
    "def generate_output(prompt):\n",
    "    try:\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "        max_length = min(512, input_ids.shape[1] + 100)  # Adjust as needed\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return output_text[len(prompt):].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM generation: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_output_grid(response_text):\n",
    "    # Attempt to extract the grid after \"Output:\"\n",
    "    if \"Output:\" in response_text:\n",
    "        output_section = response_text.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        output_section = response_text.strip()\n",
    "    grid_lines = output_section.split('\\n')\n",
    "    output_grid = []\n",
    "    for line in grid_lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            row = [int(s) for s in line.strip().split()]\n",
    "            output_grid.append(row)\n",
    "        except ValueError:\n",
    "            # Handle lines that don't contain integers\n",
    "            continue\n",
    "    if output_grid:\n",
    "        return output_grid\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def grids_are_equal(grid1, grid2):\n",
    "    # Convert grids to numpy arrays for comparison\n",
    "    grid1 = np.array(grid1)\n",
    "    grid2 = np.array(grid2)\n",
    "    return np.array_equal(grid1, grid2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test on a single example\n",
    "test_task = test_tasks[0]  # Select the first test task\n",
    "example = test_task['test'][0]  # Select the first example in the task\n",
    "\n",
    "input_grid = example['input']\n",
    "expected_output = example.get('output', None)\n",
    "\n",
    "if expected_output is not None:\n",
    "    similar_examples = retrieve_similar_examples(input_grid)  # Retrieve similar examples\n",
    "    prompt = create_prompt(similar_examples, input_grid)  # Create the prompt for the LLM\n",
    "    output_text = generate_output(prompt)  # Generate output using the LLM\n",
    "    predicted_output = extract_output_grid(output_text)  # Extract the predicted output grid\n",
    "\n",
    "    # Compare the predicted output with the expected output\n",
    "    is_correct = grids_are_equal(predicted_output, expected_output) if predicted_output else False\n",
    "\n",
    "    # Display results\n",
    "    print(f\"\\nInput Grid:\\n{grid_to_text(preprocess_grid(input_grid))}\")\n",
    "    print(f\"\\nExpected Output:\\n{grid_to_text(preprocess_grid(expected_output))}\")\n",
    "    print(f\"\\nPredicted Output:\\n{grid_to_text(preprocess_grid(predicted_output)) if predicted_output else 'None'}\")\n",
    "    print(f\"Correct: {is_correct}\")\n",
    "\n",
    "else:\n",
    "    print(\"Expected output is missing for this test example.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
