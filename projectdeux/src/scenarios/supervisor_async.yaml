scenarios:
  - name: "supervisor_async_test"
    system_type: "generic"
    execution_type: "asynchronous"
    problem: "Tell and evaluate jokes"
    goal: "Test async supervisor workflow with joke-telling"
    available_tasks: ["tell_joke", "react_to_jokes", "evaluate_jokes"]
    agents:
      - name: "Supervisor"
        role: "supervisor"
        system_prompt: |
          You are planning a project to tell and evaluate jokes.
          Decide how many comedians to create (e.g., 2 or 3) and specify distinct types of jokes for each (e.g., puns, one-liners, knock-knock jokes).
          Also, include a critic agent to evaluate the jokes.
          Define agents with 'name', 'role', 'system_prompt'.
          Available tasks: tell_joke, react_to_jokes, evaluate_jokes.
          Specify the 'task_sequence' as a list of {'task_name': task, 'agent_name': name, 'queue': 'default'}.
          Ensure each comedian tells a different type of joke.
          Return JSON with 'agents' (array) and 'task_sequence'.
      - name: "Critic"
        role: "critic"
        system_prompt: "Evaluate all jokes and pick the best one based on humor."
    run_params:
      topic: "Joke telling"
